[metadata]
query_id = 12
modalities = ["text", "image"]
required_operators = ["SEMANTIC_MAP", "SEMANTIC_CLASSIFY"]
description = """
for all items (images and description and title), create the following json:
(combined sem_map, sem_classify on both textual and image data, including hidden sem_classify in sem_map):
{"id": <product id>, "brand": <brand name", "category": <classify the images into 'topwear', 'bottomwear', (subCategory)}
"""

[definition]
# For systems that accept free-text queries
natural_language = ""
# Equivalent to the natural language query
sql = ""

# Traditional SQL query to compute the exact result on the non-omitted data.
ground_truth = """
SELECT json_object('id', id, 'brand', lower(brandName), 'category', lower(masterCategory.typeName)) as id
FROM read_parquet('styles_details.parquet')
WHERE lower(brandName) in ('adidas', 'puma');
"""

# Which accuracy metric to use for evaluation
#TODO: does f1-score make sense here? Intuitively, for generating data, I would only use precision. But because we are also filtering now means that recall also makes sense? or should we, instead of filter, project the brand name as its own column? evaluating this would be harder then because we can't do the trick with the single 'id' column anymore. maybe we can add a text to the json '<category> from <brand>' as a new sort of description.
accuracy_metric = "f1-score"
